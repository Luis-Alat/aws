{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc16340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_config' from 'c:\\\\Users\\\\XMF4277_1\\\\Documents\\\\repos\\\\aws\\\\arch_sagemaker_lambda_api-gateway\\\\notebooks\\\\my_config.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import my_config\n",
    "importlib.reload(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd3c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "<sagemaker.session.Session object at 0x0000019A9A47B620>\n",
      "sagemaker-api-lambda\n",
      "arn:aws:iam::007863746889:role/sagemaker-api-lambda-role\n"
     ]
    }
   ],
   "source": [
    "boto3_session = boto3.Session()\n",
    "sm_session = sagemaker.Session()\n",
    "\n",
    "aws_region = boto3_session.region_name\n",
    "bucket_name = my_config.bucket_name\n",
    "\n",
    "print(aws_region)\n",
    "print(sm_session)\n",
    "print(bucket_name)\n",
    "print(my_config.my_aws_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "092b7298",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID, MODEL_VERSION = my_config.model_id, \"3.0.15\"\n",
    "TRAINING_INSTANCE_TYPE = my_config.training_instance_type\n",
    "\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=MODEL_ID, model_version=MODEL_VERSION, script_scope=\"training\"\n",
    ")\n",
    "\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=MODEL_ID, model_version=MODEL_VERSION, model_scope=\"training\"\n",
    ")\n",
    "\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    model_id=MODEL_ID,\n",
    "    model_version=MODEL_VERSION,\n",
    "    image_scope=\"training\",\n",
    "    instance_type=TRAINING_INSTANCE_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748a38db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_only_top_layer': 'False',\n",
       " 'epochs': 1,\n",
       " 'batch_size': '32',\n",
       " 'optimizer': 'adamw',\n",
       " 'learning_rate': '1e-6',\n",
       " 'warmup_steps_fraction': '0.1',\n",
       " 'beta_1': '0.9',\n",
       " 'beta_2': '0.999',\n",
       " 'momentum': '0.9',\n",
       " 'epsilon': '1e-06',\n",
       " 'rho': '0.95',\n",
       " 'initial_accumulator_value': '0.1',\n",
       " 'early_stopping': 'False',\n",
       " 'early_stopping_patience': '5',\n",
       " 'early_stopping_min_delta': '0.0',\n",
       " 'dropout_rate': '0.2',\n",
       " 'regularizers_l2': '0.01',\n",
       " 'validation_split_ratio': '0.2',\n",
       " 'reinitialize_top_layer': 'Auto'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters_model = hyperparameters.retrieve_default(model_id=MODEL_ID, model_version=MODEL_VERSION)\n",
    "\n",
    "hyperparameters_model[\"batch_size\"] = \"32\"\n",
    "hyperparameters_model[\"learning_rate\"] = '1e-6'\n",
    "hyperparameters_model[\"epochs\"] = 1\n",
    "\n",
    "hyperparameters_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b930187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-api-lambda/TC/output'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_bucket = f\"jumpstart-cache-prod-{aws_region}\"\n",
    "training_data_prefix = \"training-datasets/SST/\"\n",
    "\n",
    "training_data_s3path = f\"s3://{training_data_bucket}/{training_data_prefix}\"\n",
    "\n",
    "ouput_bucket = bucket_name\n",
    "ouput_prefix = \"TC\"\n",
    "\n",
    "s3_output_location = f\"s3://{ouput_bucket}/{ouput_prefix}/output\"\n",
    "s3_output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b5c412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 256.0 KiB/3.8 MiB (246.6 KiB/s) with 1 file(s) remaining\n",
      "Completed 512.0 KiB/3.8 MiB (439.5 KiB/s) with 1 file(s) remaining\n",
      "Completed 768.0 KiB/3.8 MiB (627.8 KiB/s) with 1 file(s) remaining\n",
      "Completed 1.0 MiB/3.8 MiB (830.1 KiB/s) with 1 file(s) remaining  \n",
      "Completed 1.2 MiB/3.8 MiB (997.3 KiB/s) with 1 file(s) remaining  \n",
      "Completed 1.5 MiB/3.8 MiB (1.2 MiB/s) with 1 file(s) remaining    \n",
      "Completed 1.8 MiB/3.8 MiB (1.3 MiB/s) with 1 file(s) remaining    \n",
      "Completed 2.0 MiB/3.8 MiB (1.5 MiB/s) with 1 file(s) remaining    \n",
      "Completed 2.2 MiB/3.8 MiB (1.7 MiB/s) with 1 file(s) remaining    \n",
      "Completed 2.5 MiB/3.8 MiB (1.8 MiB/s) with 1 file(s) remaining    \n",
      "Completed 2.8 MiB/3.8 MiB (2.0 MiB/s) with 1 file(s) remaining    \n",
      "Completed 3.0 MiB/3.8 MiB (2.2 MiB/s) with 1 file(s) remaining    \n",
      "Completed 3.2 MiB/3.8 MiB (2.3 MiB/s) with 1 file(s) remaining    \n",
      "Completed 3.5 MiB/3.8 MiB (2.5 MiB/s) with 1 file(s) remaining    \n",
      "Completed 3.8 MiB/3.8 MiB (2.7 MiB/s) with 1 file(s) remaining    \n",
      "Completed 3.8 MiB/3.8 MiB (2.7 MiB/s) with 1 file(s) remaining    \n",
      "download: s3://jumpstart-cache-prod-us-east-1/training-datasets/SST/data.csv to data\\sst2\\data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $training_data_s3path data/sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a2df900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0       hide new secretions from the parental units \n",
       "1      0               contains no wit , only labored gags \n",
       "2      1  that loves its characters and communicates som...\n",
       "3      0  remains utterly satisfied to remain the same t...\n",
       "4      0  on the worst revenge-of-the-nerds clichés the ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df = pd.read_csv(\"data/sst2/data.csv\", header=None)\n",
    "training_data_df.columns = [\"label\", \"text\"]\n",
    "\n",
    "training_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1bae4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68221, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30958494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only a fraction to train because computational power\n",
    "train_df, test_df = train_test_split(training_data_df, train_size=0.01, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b14e09bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34863</th>\n",
       "      <td>1</td>\n",
       "      <td>venturesome , beautifully realized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12635</th>\n",
       "      <td>0</td>\n",
       "      <td>of self-congratulation between actor and direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50129</th>\n",
       "      <td>0</td>\n",
       "      <td>a pact to burn the negative and the script and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40766</th>\n",
       "      <td>1</td>\n",
       "      <td>-- conrad l. hall 's cinematography will likel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34223</th>\n",
       "      <td>0</td>\n",
       "      <td>that it makes your least favorite james bond m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "34863      1                venturesome , beautifully realized \n",
       "12635      0  of self-congratulation between actor and direc...\n",
       "50129      0  a pact to burn the negative and the script and...\n",
       "40766      1  -- conrad l. hall 's cinematography will likel...\n",
       "34223      0  that it makes your least favorite james bond m..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3b8bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/sst2/train.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91132f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Uploading local file to s3\n",
    "prefix_s3 = \"TC\"\n",
    "target_s3_file_path = \"train/data.csv\"\n",
    "\n",
    "local_train_file_path = \"data/sst2/train.csv\"\n",
    "\n",
    "s3_full_path_target = f\"{prefix_s3}/{target_s3_file_path}\"\n",
    "\n",
    "boto3_session.resource(\"s3\").Bucket(bucket_name).Object(s3_full_path_target).upload_file(local_train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = f\"{my_config.solution_prefix}-tc-finetune\"\n",
    "\n",
    "tc_estimator = Estimator(\n",
    "    role=my_config.my_aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=TRAINING_INSTANCE_TYPE,\n",
    "    max_run=3500,\n",
    "    hyperparameters=hyperparameters_model,\n",
    "    output_path=s3_output_location,\n",
    "    tags=[{\"Key\": my_config.tag_key, \"Value\": my_config.solution_prefix}],\n",
    "    base_job_name=training_job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f6287c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-api-lambda/TC/train'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_path_updated = f\"s3://{bucket_name}/{prefix_s3}/train\"\n",
    "training_data_path_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b528d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-soln-documents--tc-finetune-2025-06-19-18-38-02-665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-19 18:38:05 Starting - Starting the training job...\n",
      "2025-06-19 18:38:21 Starting - Preparing the instances for training...\n",
      "2025-06-19 18:39:11 Downloading - Downloading the training image......\n",
      "2025-06-19 18:39:58 Training - Training image download completed. Training in progress.2025-06-19 18:40:05.236392: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2025-06-19 18:40:05.236548: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2025-06-19 18:40:05.261177: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2025-06-19 18:40:07,186 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "2025-06-19 18:40:07,198 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2025-06-19 18:40:07,406 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2025-06-19 18:40:07,424 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2025-06-19 18:40:07,442 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2025-06-19 18:40:07,451 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c4.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": \"32\",\n",
      "        \"beta_1\": \"0.9\",\n",
      "        \"beta_2\": \"0.999\",\n",
      "        \"dropout_rate\": \"0.2\",\n",
      "        \"early_stopping\": \"False\",\n",
      "        \"early_stopping_min_delta\": \"0.0\",\n",
      "        \"early_stopping_patience\": \"5\",\n",
      "        \"epochs\": 1,\n",
      "        \"epsilon\": \"1e-06\",\n",
      "        \"initial_accumulator_value\": \"0.1\",\n",
      "        \"learning_rate\": \"1e-6\",\n",
      "        \"momentum\": \"0.9\",\n",
      "        \"optimizer\": \"adamw\",\n",
      "        \"regularizers_l2\": \"0.01\",\n",
      "        \"reinitialize_top_layer\": \"Auto\",\n",
      "        \"rho\": \"0.95\",\n",
      "        \"train_only_top_layer\": \"False\",\n",
      "        \"validation_split_ratio\": \"0.2\",\n",
      "        \"warmup_steps_fraction\": \"0.1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c4.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"sagemaker-soln-documents--tc-finetune-2025-06-19-18-38-02-665\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/tensorflow/transfer_learning/tc/prepack/v1.1.0/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c4.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c4.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":1,\"epsilon\":\"1e-06\",\"initial_accumulator_value\":\"0.1\",\"learning_rate\":\"1e-6\",\"momentum\":\"0.9\",\"optimizer\":\"adamw\",\"regularizers_l2\":\"0.01\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_steps_fraction\":\"0.1\"}\n",
      "SM_USER_ENTRY_POINT=transfer_learning.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
      "SM_INPUT_DATA_CONFIG={\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"model\",\"training\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.c4.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=transfer_learning\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/tensorflow/transfer_learning/tc/prepack/v1.1.0/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c4.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":\"32\",\"beta_1\":\"0.9\",\"beta_2\":\"0.999\",\"dropout_rate\":\"0.2\",\"early_stopping\":\"False\",\"early_stopping_min_delta\":\"0.0\",\"early_stopping_patience\":\"5\",\"epochs\":1,\"epsilon\":\"1e-06\",\"initial_accumulator_value\":\"0.1\",\"learning_rate\":\"1e-6\",\"momentum\":\"0.9\",\"optimizer\":\"adamw\",\"regularizers_l2\":\"0.01\",\"reinitialize_top_layer\":\"Auto\",\"rho\":\"0.95\",\"train_only_top_layer\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_steps_fraction\":\"0.1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-soln-documents--tc-finetune-2025-06-19-18-38-02-665\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/tensorflow/transfer_learning/tc/prepack/v1.1.0/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c4.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c4.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"transfer_learning.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"32\",\"--beta_1\",\"0.9\",\"--beta_2\",\"0.999\",\"--dropout_rate\",\"0.2\",\"--early_stopping\",\"False\",\"--early_stopping_min_delta\",\"0.0\",\"--early_stopping_patience\",\"5\",\"--epochs\",\"1\",\"--epsilon\",\"1e-06\",\"--initial_accumulator_value\",\"0.1\",\"--learning_rate\",\"1e-6\",\"--momentum\",\"0.9\",\"--optimizer\",\"adamw\",\"--regularizers_l2\",\"0.01\",\"--reinitialize_top_layer\",\"Auto\",\"--rho\",\"0.95\",\"--train_only_top_layer\",\"False\",\"--validation_split_ratio\",\"0.2\",\"--warmup_steps_fraction\",\"0.1\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "SM_HP_BATCH_SIZE=32\n",
      "SM_HP_BETA_1=0.9\n",
      "SM_HP_BETA_2=0.999\n",
      "SM_HP_DROPOUT_RATE=0.2\n",
      "SM_HP_EARLY_STOPPING=False\n",
      "SM_HP_EARLY_STOPPING_MIN_DELTA=0.0\n",
      "SM_HP_EARLY_STOPPING_PATIENCE=5\n",
      "SM_HP_EPOCHS=1\n",
      "SM_HP_EPSILON=1e-06\n",
      "SM_HP_INITIAL_ACCUMULATOR_VALUE=0.1\n",
      "SM_HP_LEARNING_RATE=1e-6\n",
      "SM_HP_MOMENTUM=0.9\n",
      "SM_HP_OPTIMIZER=adamw\n",
      "SM_HP_REGULARIZERS_L2=0.01\n",
      "SM_HP_REINITIALIZE_TOP_LAYER=Auto\n",
      "SM_HP_RHO=0.95\n",
      "SM_HP_TRAIN_ONLY_TOP_LAYER=False\n",
      "SM_HP_VALIDATION_SPLIT_RATIO=0.2\n",
      "SM_HP_WARMUP_STEPS_FRACTION=0.1\n",
      "PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages:/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument-3.4.2-py3.9.egg:/usr/local/lib/python3.9/site-packages/pyinstrument_cext-0.2.4-py3.9-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/usr/local/bin/python3.9 transfer_learning.py --batch_size 32 --beta_1 0.9 --beta_2 0.999 --dropout_rate 0.2 --early_stopping False --early_stopping_min_delta 0.0 --early_stopping_patience 5 --epochs 1 --epsilon 1e-06 --initial_accumulator_value 0.1 --learning_rate 1e-6 --momentum 0.9 --optimizer adamw --regularizers_l2 0.01 --reinitialize_top_layer Auto --rho 0.95 --train_only_top_layer False --validation_split_ratio 0.2 --warmup_steps_fraction 0.1\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still available.\n",
      "Installing dependencies from /opt/ml/code/tensorflow_requirements.txt\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "Processing ./lib/sagemaker_jumpstart_prepack_script_utilities/sagemaker_jumpstart_prepack_script_utilities-1.0.0-py2.py3-none-any.whl\n",
      "Installing collected packages: sagemaker-jumpstart-prepack-script-utilities\n",
      "Successfully installed sagemaker-jumpstart-prepack-script-utilities-1.0.0\n",
      "2025-06-19 18:40:10.032504: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2025-06-19 18:40:10.032659: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2025-06-19 18:40:10.056012: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "Running training scripts with arguments: Namespace(model_dir='/opt/ml/model', train='/opt/ml/input/data/training', validation=None, pretrained_model='/opt/ml/input/data/model', hosts=['algo-1'], current_host='algo-1', verbose_one_line_per_epoch=2, model_url=None, text_processor_url=None, checkpoint_save_best_only='True', seed=123, warmup_steps_fraction=0.1, reinitialize_top_layer='Auto', train_only_top_layer='False', validation_split_ratio=0.2, early_stopping='False', early_stopping_patience=5, early_stopping_min_delta=0.0, dropout_rate=0.2, regularizers_l2=0.01, epochs=1, batch_size=32, optimizer='adamw', learning_rate=1e-06, beta_1=0.9, beta_2=0.999, epsilon=1e-06, momentum=0.9, rho=0.95, initial_accumulator_value=0.1).\n",
      "Ignoring unrecognized arguments: [].\n",
      "Number of class labels: 2\n",
      "Cardinality of dataset 682\n",
      "Number of training examples: 545\n",
      "Number of validation examples: 137\n",
      "'_input_model_extracted/__models_info__.json' file could not be found.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Attaching a randomly initialized classification layer on top of the original encoder layer model to classify input text to one of the 2 classes.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non\n",
      "e, 128)}\n",
      "keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[1][0]',            \n",
      "                                768),                             'keras_layer[1][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[1][2]']\n",
      "[(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),\n",
      "(None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}\n",
      "dropout (Dropout)              (None, 768)          0           ['keras_layer_1[1][13]']\n",
      "classifier (Dense)             (None, 2)            1538        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,779\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "using Adamw optimizer\n",
      "gradient_clip_norm=1.000000\n",
      "Setting the evaluation metric to: val_accuracy.\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.9/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-39-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still available.\n",
      "[2025-06-19 18:40:29.270 ip-10-2-83-144.ec2.internal:37 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/usr/local/lib/python3.9/site-packages/smdebug-1.0.26b20230119-py3.9.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2025-06-19 18:40:29.492 ip-10-2-83-144.ec2.internal:37 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2025-06-19 18:40:29.512 ip-10-2-83-144.ec2.internal:37 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2025-06-19 18:40:29.513 ip-10-2-83-144.ec2.internal:37 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2025-06-19 18:40:29.513 ip-10-2-83-144.ec2.internal:37 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2025-06-19 18:40:29.514 ip-10-2-83-144.ec2.internal:37 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[2025-06-19 18:40:29.514 ip-10-2-83-144.ec2.internal:37 INFO hook.py:427] Monitoring the collections: metrics, losses, sm_metrics\n",
      "18/18 - 191s - loss: 1.1731 - accuracy: 0.5450 - val_loss: 1.0190 - val_accuracy: 0.6131 - 191s/epoch - 11s/step\n",
      "Setting weights to model achieving the maximum val_accuracy: 0.6131386756896973 at epoch 1/1\n",
      "Saving the model with the highest val_accuracy for running inference or incremental training.\n",
      "Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 364). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: /opt/ml/model/1/assets\n",
      "Assets written to: /opt/ml/model/1/assets\n",
      "Info file not found at '_input_model_extracted/__models_info__.json'.\n",
      "2025-06-19 18:44:01,311 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-06-19 18:44:01,311 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-06-19 18:44:01,312 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2025-06-19 18:44:26 Uploading - Uploading generated training model\n",
      "2025-06-19 18:44:26 Completed - Training job completed\n",
      "Training seconds: 345\n",
      "Billable seconds: 345\n"
     ]
    }
   ],
   "source": [
    "tc_estimator.fit({\"training\": training_data_path_updated}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61cb7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_INSTANCE_TYPE = my_config.inference_instance_type\n",
    "\n",
    "deply_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=MODEL_ID,\n",
    "    model_version=MODEL_VERSION,\n",
    "    instance_type=INFERENCE_INSTANCE_TYPE\n",
    ")\n",
    "\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=MODEL_ID, model_version=MODEL_VERSION, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "unique_hash = str(uuid.uuid4())[:6]\n",
    "endpoint_name_tc_finetune = f\"{my_config.solution_prefix}-{unique_hash}-tc-finetune-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cbce2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-007863746889\n",
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-api-lambda/TC/output/sagemaker-soln-documents--tc-finetune-2025-06-19-18-38-02-665/output/model.tar.gz), script artifact (s3://jumpstart-cache-prod-us-east-1/source-directory-tarballs/tensorflow/inference/tc/v2.0.0/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-007863746889/sagemaker-jumpstart-2025-06-19-19-27-14-161/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: sagemaker-jumpstart-2025-06-19-19-27-14-161\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-soln-documents--0e0686-tc-finetune-endpoint\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-soln-documents--0e0686-tc-finetune-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--!"
     ]
    }
   ],
   "source": [
    "finetuned_predictor = tc_estimator.deploy(\n",
    "\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deply_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name_tc_finetune,\n",
    "    serverless_inference_config=ServerlessInferenceConfig()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf348944",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data_endpoint = test_df[:32]\n",
    "\n",
    "ground_truth, test_examples = (\n",
    "    inference_data_endpoint.iloc[:, 0].values.tolist(),\n",
    "    inference_data_endpoint.iloc[:, 1].values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "378e3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_endpoint(text, predictor):\n",
    "    response = predictor.predict(\n",
    "        text,\n",
    "        {\"ContentType\": \"application/x-text\", \"Accept\": \"application/json;verbose\"}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response)\n",
    "    probabilities, labels, predicted_label = (\n",
    "        model_predictions[\"probabilities\"],\n",
    "        model_predictions[\"labels\"],\n",
    "        model_predictions[\"predicted_label\"]\n",
    "    )\n",
    "    return probabilities, labels, predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e48bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob_list, predict_label_list = list(), list()\n",
    "\n",
    "for text in test_examples:\n",
    "    \n",
    "    query_response = query_endpoint(text.encode(\"utf-8\"), finetuned_predictor)\n",
    "    probabilities, labels, predicted_labels = parse_response(query_response)  \n",
    "    \n",
    "    predict_prob_list.append(probabilities)\n",
    "    predict_label_list.append(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12a16e",
   "metadata": {},
   "source": [
    "Configurar función lambda en aws (habilita permisos con sagemaker para invocar endpoints) para invocar el endpoint del modelo. Configurar las variables de entorno pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ebcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Grab environment variables\n",
    "ENDPOINT_NAME = os.environ['ENDPOINT_NAME'] # Configurado en variables de ambiente del AWS\n",
    "runtime = boto3.client('runtime.sagemaker') # Asegurarse de que la función tiene permisos de invocación de endpoints\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "    \n",
    "    # Assuming the input is in the format {'text': 'your text here'}\n",
    "    data = json.loads(json.dumps(event))\n",
    "    text = data['text']\n",
    "    \n",
    "    # Encode the text\n",
    "    encoded_text = text.encode('utf-8')\n",
    "    \n",
    "    # Query the endpoint\n",
    "    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                       ContentType='application/x-text',\n",
    "                                       Accept='application/json;verbose',\n",
    "                                       Body=encoded_text)\n",
    "\n",
    "    print(\"Raw response:\", response)\n",
    "\n",
    "    # Parse the response\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "    print(\"Parsed response:\", response_body)\n",
    "\n",
    "    probabilities = response_body['probabilities']\n",
    "    labels = response_body['labels']\n",
    "    predicted_label = response_body['predicted_label']\n",
    "    \n",
    "    # Convert predicted_label to 'Positive' or 'Negative'\n",
    "    sentiment = 'Positive' if predicted_label == 1 else 'Negative'\n",
    "    \n",
    "    result = {\n",
    "        'sentiment': sentiment,\n",
    "        'probabilities': probabilities,\n",
    "        'labels': labels\n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130f3ed",
   "metadata": {},
   "source": [
    "Crear una API REST (APY-GATEWAY) para comunicarse entre el cliente, con la función y lambda y luego la función con el endpoint. Crear método referenciando a la lambda creada y hacer un deploy del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c47288",
   "metadata": {},
   "source": [
    "Se hace un request a la API usando el URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f457c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_uri = \"https://9awwa68h1k.execute-api.us-east-1.amazonaws.com/DEPLOYMENT_ENV\"\n",
    "resource_path = \"text-clasification-funetune-model\"\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{api_uri}/{resource_path}\",\n",
    "    data=json.dumps({\"text\": \"I loved this movie. It was amazing\"})\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7da3d154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"sentiment\": \"Positive\", \"probabilities\": [0.0652378, 0.93476218], \"labels\": [0, 1]}'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0809c70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: sagemaker-jumpstart-2025-06-19-19-27-14-161\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: sagemaker-soln-documents--0e0686-tc-finetune-endpoint\n",
      "INFO:sagemaker:Deleting endpoint with name: sagemaker-soln-documents--0e0686-tc-finetune-endpoint\n"
     ]
    }
   ],
   "source": [
    "# Liberamos el modelo y el endpoint para no incurrir en posibles gastos (aunque fue severless)\n",
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a15b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sg_lambda_api_gate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
